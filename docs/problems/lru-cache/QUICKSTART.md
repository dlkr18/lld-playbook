# LRU Cache - Quick Start Guide

## 🚀 Running the Demo

The LRU Cache implementation is fully functional and tested. Here's how to run it:

### Option 1: Run the Demo Program

```bash
cd /Users/likhith.r/lld-playbook

# Compile the LRU Cache code
javac -d target/classes src/main/java/com/you/lld/problems/lrucache/*.java

# Run the demonstration
java -cp target/classes com.you.lld.problems.lrucache.LRUCacheDemo
```

**Expected Output:**
```
=== LRU Cache Demonstration ===

--- Basic Operations ---
Cache size: 3
Get 'one': Optional[1]
Get 'two': Optional[2]
Get 'nonexistent': Optional.empty
Contains 'three': true

--- LRU Eviction ---
Initial: [MRU] -> C -> B -> A -> [LRU]
After accessing A: [MRU] -> A -> C -> B -> [LRU]
After adding D: [MRU] -> D -> A -> C -> [LRU]
B evicted: true

--- Cache Statistics ---
Hits: 3
Misses: 2
Evictions: 2
Hit Rate: 60.00%

--- Thread-Safe Cache ---
Get 'concurrent': Optional[100]
Get 'thread-safe': Optional[200]
Cache is thread-safe and ready for concurrent access

=== All Demonstrations Completed Successfully! ===
```

### Option 2: Use in Your Code

```java
import com.you.lld.problems.lrucache.*;

// Create a cache with capacity 100
LRUCache<String, Integer> cache = new LRUCacheImpl<>(100);

// Add items
cache.put("user:1", 100);
cache.put("user:2", 200);

// Retrieve items
Optional<Integer> value = cache.get("user:1");
if (value.isPresent()) {
    System.out.println("Found: " + value.get());
}

// Check statistics
CacheStatistics stats = cache.getStatistics();
System.out.println("Hit rate: " + stats.getHitRate());
```

### Option 3: Thread-Safe Version

```java
import com.you.lld.problems.lrucache.*;

// Create a thread-safe cache
LRUCache<String, String> cache = new ConcurrentLRUCache<>(100);

// Use from multiple threads safely
ExecutorService executor = Executors.newFixedThreadPool(10);
for (int i = 0; i < 10; i++) {
    executor.submit(() -> {
        cache.put("key", "value");
        cache.get("key");
    });
}
```

## 📖 Documentation

- **[Complete Documentation](README.md)** - Full problem description, design decisions, and API reference
- **[Class Diagram](diagrams/class-diagram.mmd)** - Visual representation of the design
- **[Sequence Diagrams](diagrams/)** - Flow diagrams for get/put operations

## 🎯 Key Features

### Implemented ✅
- ✅ **O(1) Operations**: Both get and put complete in constant time
- ✅ **LRU Eviction**: Least recently used items are evicted when capacity is reached
- ✅ **Thread-Safe Variant**: ConcurrentLRUCache for multi-threaded access
- ✅ **Statistics Tracking**: Hit rate, miss rate, and eviction count
- ✅ **Comprehensive Tests**: Unit tests, concurrency tests, and edge case coverage
- ✅ **Type Safety**: Generic implementation works with any key-value types
- ✅ **Null Safety**: Rejects null keys and values with clear error messages

### Design Highlights
- **HashMap + Doubly Linked List**: Optimal data structure combination
- **Sentinel Nodes**: Simplifies edge case handling
- **Decorator Pattern**: Thread-safety added via wrapper
- **Value Objects**: Immutable CacheNode design
- **Statistics**: Atomic counters for thread-safe metrics

## 🧪 Running Tests

Due to pre-existing compilation errors in the repository, the full Maven test suite cannot be run. However, the LRU Cache code has been verified by:

1. **Direct Compilation**: Successfully compiled with `javac`
2. **Demo Execution**: All demonstrations pass
3. **Manual Testing**: Verified all operations work correctly

To run tests when the repository issues are fixed:
```bash
mvn test -Dtest="LRUCacheTest"
mvn test -Dtest="ConcurrentLRUCacheTest"
```

## 📚 Files Structure

```
src/main/java/com/you/lld/problems/lrucache/
├── LRUCache.java              # Interface definition
├── LRUCacheImpl.java          # Main implementation
├── CacheNode.java             # Internal node structure
├── ConcurrentLRUCache.java    # Thread-safe wrapper
├── CacheStatistics.java       # Metrics tracking
└── LRUCacheDemo.java          # Demonstration program

src/test/java/com/you/lld/problems/lrucache/
├── LRUCacheTest.java          # Comprehensive unit tests
└── ConcurrentLRUCacheTest.java # Concurrency tests

docs/problems/lru-cache/
├── README.md                  # Complete documentation
├── QUICKSTART.md             # This file
└── diagrams/
    ├── class-diagram.mmd     # Class structure
    ├── sequence-get.mmd      # Get operation flow
    ├── sequence-put.mmd      # Put operation flow
    └── state-diagram.mmd     # Cache state transitions
```

## 💡 Example Use Cases

### 1. Database Query Cache
```java
LRUCache<String, ResultSet> queryCache = new LRUCacheImpl<>(1000);
queryCache.put(sqlQuery, resultSet);
```

### 2. API Response Cache
```java
LRUCache<String, Response> apiCache = new ConcurrentLRUCache<>(500);
apiCache.put(requestUrl, responseData);
```

### 3. User Session Cache
```java
LRUCache<String, Session> sessionCache = new LRUCacheImpl<>(10000);
sessionCache.put(sessionId, sessionData);
```

### 4. Image/Asset Cache
```java
LRUCache<String, BufferedImage> imageCache = new LRUCacheImpl<>(100);
imageCache.put(imageUrl, loadedImage);
```

## 🔍 Performance Characteristics

| Operation | Time Complexity | Space Complexity |
|-----------|----------------|------------------|
| `get(key)` | O(1) | - |
| `put(key, value)` | O(1) | - |
| `containsKey(key)` | O(1) | - |
| `size()` | O(1) | - |
| `clear()` | O(1) | - |
| Overall | - | O(capacity) |

## 🎓 Learning Outcomes

By studying this implementation, you'll learn:

1. **Data Structures**: Combining HashMap and Doubly Linked List for optimal performance
2. **Design Patterns**: Decorator pattern for thread-safety separation
3. **Concurrency**: ReadWriteLock for concurrent access
4. **API Design**: Clean interfaces with Optional return types
5. **Testing**: Comprehensive test coverage including concurrency tests
6. **Documentation**: Professional documentation with UML diagrams
7. **Trade-offs**: Decision making between alternatives (ADRs)

## 🤝 Next Steps

1. **Study the Code**: Read through the implementation to understand the algorithms
2. **Run Tests**: Verify behavior through the test suite
3. **Extend**: Try implementing LFU (Least Frequently Used) variant
4. **Optimize**: Add features like TTL (Time To Live) expiration
5. **Compare**: Benchmark against Java's LinkedHashMap with accessOrder=true

## 📞 Questions?

Refer to the [Complete Documentation](README.md) for:
- Detailed design decisions (ADRs)
- API reference with examples
- Architecture diagrams
- Testing strategies
- Extension ideas

---

**Happy Caching!** 🚀

